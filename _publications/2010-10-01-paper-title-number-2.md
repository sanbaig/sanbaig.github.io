---
title: "Octopus Tentacle-Inspired In-Sensor Adaptive Integral for Edge-Intelligent Touch Intention Recognition"
collection: publications
category: manuscripts
permalink: /publication/2025-06-08-paper-title-number-5
excerpt: 'Chao Wei, Shifan Yu, Yifan Meng, Yijing Xu, Yu Hu, Zhicheng Cao, Zijian Huang, Lei Liu, <strong><u>Yanhao Luo</u></strong>, Hongyu Chen, Zhong Chen, Zeliang Zhang, Liang Wang, Zhenyu Zhao, Yuanjin Zheng, Qingliang Liao, Xinqin Liao\*'
date: 2025-07-10
venue: 'Advanced Functional Materials'
#paperurl: 'http://academicpages.github.io/files/paper3.pdf'
#citation: 'Your Name, You. (2024). &quot;Paper Title Number 3.&quot; <i>GitHub Journal of Bugs</i>. 1(3).'
---

Electronics continue to drive technological innovation and diversified applications. To ensure efficiency and effectiveness across various interactive contexts, the ability to adjust operating functions or parameters according to environmental shifts or user requirements is highly desirable. However, due to the inherent limitations of nonadaptive device structures and materials, the current development of touch electronics faces challenges, e.g., limited hardware resources, poor adaptability, weak deformation stability, and bottlenecks in sensing data processing. Here, a reconfigurable and adaptive intelligent (RAI) touch sensor is proposed, inspired by octopus's tentacle cognitive behavior. It realizes remarkable deformability and highly efficient multitouch interactions. The geometric progression structure of the sensing element equips the RAI touch sensor with a unique integrated-in-sensing mechanism and programmable logic. This greatly compresses sensing data dimensionality at the edge, yielding concise and undistorted interactive signals. By leveraging the advantages of hard-soft bonding and interface modulation of functional materials, the adaptability is achieved with a 200% strain range a 180Â° twist tolerance, and exceptional deformation stability of >10 000 cycles. The diverse application-specific configurations of the RAI touch sensor, enable a dynamic intention recognition accuracy of over 99%, advancing next-generation Internet of Things and edge computing research and innovation.
